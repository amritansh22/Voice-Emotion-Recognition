import numpy as np
import pandas as pd
import librosa
import matplotlib.pyplot as plt

"""
d = []
i=1
j=1

for i in range(4):
 y, sample_rate = librosa.load(str(j)+'.wav')
 librosa.feature.mfcc(y=y, sr=sample_rate)
 d.append(y)
 j = j+1


dd = []
i=1
j=1
for i in range(2):
 y, sample_rate = librosa.load('s'+str(j)+'.wav')
 librosa.feature.mfcc(y=y, sr=sample_rate)
 dd.append(y)
 j = j+1
 
 
 """
 """
import FFmpeg
y, sr = librosa.load(librosa.util.example_audio_file(), duration=5.0) 
y, sample_rate = librosa.load('delete.wav')
import soundfile
y, sr = librosa.load('d (10).wav')
y_changed = librosa.effects.time_stretch(y, rate=1.06)
y_changed = np.float16(y_changed)
librosa.output.write_wav('delete.wav' ,y_changed, sr)
j=j+1
"""

"""
test
"""
df = pd.DataFrame(columns=['feature'])
bookmark=0
for i in range(12480):
 y, sample_rate = librosa.load('Actor_01/d (' +str(i+1)+ ').wav')
 sample_rate = np.array(sample_rate)
 mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sample_rate, n_mfcc=13),axis=0)
 feature = mfccs
 
 df.loc[bookmark] = [feature]
 bookmark=bookmark+1
df3 = pd.DataFrame(df['feature'].values.tolist())

"""
#data agumentation



y, sr = librosa.load('asdfgh/a (1).wav')






dfw = pd.DataFrame(columns=['feature'])
bookmark=0
j=11232
for i in range(1248):
 y, sr = librosa.load('d (' +str(i+1)+ ').wav')
 y_changed = librosa.effects.time_stretch(y, rate=1.06)
 librosa.output.write_wav('d (' + str(j+1) + ').wav' ,y_changed, sr)
 j=j+1

j=1248
for i in range(1248):
 y, sr = librosa.load('d (' +str(i+1)+ ').wav')
 y_changed = librosa.effects.pitch_shift(y, sample_rate, n_steps=-2)
 librosa.output.write_wav('d (' + str(i+1) + ').wav' ,y_changed, sr)
 j=j+1


j=1248
for i in range(1248):
 y, sr = librosa.load('d (' +str(i+1)+ ').wav')
 y_changed = librosa.effects.pitch_shift(y, sample_rate, n_steps=-3)
 librosa.output.write_wav('d (' + str(i+1) + ').wav' ,y_changed, sr)
 j=j+1
 
 
 
j=192
for i in range(192):
 y, sr = librosa.load('a (' +str(i+1)+ ').wav')  
 wn = np.random.randn(len(y))
 y_changed = y + 0.005*wn
 soundfile.write('a (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1
 
j=384
for i in range(192):
 y, sr = librosa.load('a (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.time_stretch(y, rate=0.8)
 soundfile.write('a (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1 
 
j=576
for i in range(192):
 y, sr = librosa.load('a (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.time_stretch(y, rate=1.06)
 soundfile.write('a (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1  
 
 
j=768
for i in range(192):
 y, sr = librosa.load('a (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.pitch_shift(y, sr, n_steps=1)
 soundfile.write('a (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1  


j=960
for i in range(192):
 y, sr = librosa.load('a (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.pitch_shift(y, sr, n_steps=2)
 soundfile.write('a (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1  


j=1152
for i in range(192):
 y, sr = librosa.load('a (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.pitch_shift(y, sr, n_steps=3)
 soundfile.write('a (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1  


j=1344
for i in range(192):
 y, sr = librosa.load('a (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.pitch_shift(y, sr, n_steps=-1)
 soundfile.write('a (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1  


j=1536
for i in range(192):
 y, sr = librosa.load('a (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.pitch_shift(y, sr, n_steps=-2)
 soundfile.write('a (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1  


j=1728
for i in range(192):
 y, sr = librosa.load('a (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.pitch_shift(y, sr, n_steps=-3)
 soundfile.write('a (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1   









 
j=1248
for i in range(1248):
 y, sr = librosa.load('d (' +str(i+1)+ ').wav')  
 wn = np.random.randn(len(y))
 y_changed = y + 0.005*wn
 soundfile.write('d (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1
 
j=2496
for i in range(1248):
 y, sr = librosa.load('d (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.time_stretch(y, rate=0.8)
 soundfile.write('d (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1 
 
j=3744
for i in range(1248):
 y, sr = librosa.load('d (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.time_stretch(y, rate=1.06)
 soundfile.write('d (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1  
 
 
j=4992
for i in range(1248):
 y, sr = librosa.load('d (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.pitch_shift(y, sr, n_steps=1)
 soundfile.write('d (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1  


j=6240
for i in range(1248):
 y, sr = librosa.load('d (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.pitch_shift(y, sr, n_steps=2)
 soundfile.write('d (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1  

j=7488
for i in range(1248):
 y, sr = librosa.load('d (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.pitch_shift(y, sr, n_steps=3)
 soundfile.write('d (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1  


j=8736
for i in range(1248):
 y, sr = librosa.load('d (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.pitch_shift(y, sr, n_steps=-1)
 soundfile.write('d (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1  


j=9984
for i in range(1248):
 y, sr = librosa.load('d (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.pitch_shift(y, sr, n_steps=-2)
 soundfile.write('d (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1  


j=11232
for i in range(1248):
 y, sr = librosa.load('d (' +str(i+1)+ ').wav')  
 y_changed = librosa.effects.pitch_shift(y, sr, n_steps=-3)
 soundfile.write('d (' +str(j+1)+ ').wav',y_changed, sr)
 j=j+1   






for i in range(1248):
 y, sample_rate = librosa.load('drive/My Drive/dataset/'+'dw'+str(i+1)+'.wav')
 sample_rate = np.array(sample_rate)
 mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sample_rate, n_mfcc=13),axis=0)
 feature = mfccs
 
 df.loc[bookmark] = [feature]
 bookmark=bookmark+1
                          
                         
df3 = pd.DataFrame(df['feature'].values.tolist())



import IPython.display as ipd
y, sr = librosa.load('a (10).wav')
y_changed = librosa.effects.time_stretch(y, rate=0.80)
#librosa.output.write_wav('delll.wav' ,y_changed, sr)
ipd.Audio(y_changed, rate=sr)
soundfile.write('dell.wav',y_changed,sr)
y, sr = librosa.load('delll.wav')

import soundfile
import IPython.display as ipd
y, sample_rate = librosa.load('a (100).wav')
data = librosa.effects.pitch_shift(y, sample_rate, n_steps=1)
ipd.Audio(y, rate=sample_rate)

y, sample_rate = librosa.load('drive/My Drive/dd/d (200).wav')
data = librosa.effects.pitch_shift(y, sample_rate, n_steps=1)
ipd.Audio(data, rate=sample_rate)

y, sample_rate = librosa.load('drive/My Drive/dd/d (200).wav')
data = librosa.effects.pitch_shift(y, sample_rate, n_steps=-1)
ipd.Audio(data, rate=sample_rate)

y, sample_rate = librosa.load('drive/My Drive/dd/du (200).wav')
data = librosa.effects.pitch_shift(y, sample_rate, n_steps=1)
ipd.Audio(y, rate=sample_rate)
data agumentation 2 
"""

dfs = pd.DataFrame(columns=['feature'])
bookmark=0
for i in range(1920):
 y, sample_rate = librosa.load('asdfgh/a (' +str(i+1)+ ').wav')
 sample_rate = np.array(sample_rate)
 mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sample_rate, n_mfcc=13),axis=0)
 feature = mfccs
 #librosa.feature.mfcc(y=y, sr=sample_rate)
 #j = j+1
 dfs.loc[bookmark] = [feature]
 bookmark=bookmark+1 
df4 = pd.DataFrame(dfs['feature'].values.tolist())
df3 = df3.assign(label = 0)
df4 = df4.assign(label = 1)
df8 = df3.append(df4)[df4.columns.tolist()]
df8=df8.fillna(0)
from sklearn.utils import shuffle
df8 = shuffle(df8)

"""
newdf1 = np.random.rand(len(df8)) < 0.5
train = df8[newdf1]
test = df8[~newdf1]
trainfeatures = train.iloc[:, :-1]
trainlabel = train.iloc[:, -1:]
testfeatures = test.iloc[:, :-1]
testlabel = test.iloc[:, -1:]
X_train = np.array(trainfeatures)
y_train = np.array(trainlabel)
X_test = np.array(testfeatures)
y_test = np.array(testlabel)
x_traincnn =np.expand_dims(X_train, axis=2)
x_testcnn= np.expand_dims(X_test, axis=2)
"""

X = df8.iloc[:,:-1]
y = df8.iloc[:,-1:]
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

#print(X_train.shape)
#print(X_test.shape)

x_traincnn =np.expand_dims(X_train, axis=2)
x_testcnn =np.expand_dims(X_test, axis=2)

#print(X.shape)
#print(y.shape)
#print(x_traincnn.shape)
#print(x_testcnn.shape)

from keras.optimizers import SGD
opt = SGD(lr=1e-8)

#ANN
import keras
from keras.models import Sequential
from keras.layers import Dense
keras.layers.Dropout(0.5, noise_shape=None, seed=None)
classifier = Sequential()
classifier.add(Dense(output_dim = 110, init = 'uniform', activation = 'relu', input_dim = 220))
#classifier.add(Dense(output_dim = 110, init = 'uniform', activation = 'relu'))
#classifier.add(Dense(output_dim = 110, init = 'uniform', activation = 'relu'))
classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))
classifier.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])
classifier.fit(X_train, y_train, batch_size = 56, nb_epoch = 50)
y_pred = classifier.predict(X_test)
y_pred = (y_pred > 0.5)
from sklearn.metrics import confusion_matrix

#CNN
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Conv1D, MaxPooling1D,Dropout
from keras.layers import Flatten
model = Sequential()
model.add(Conv1D(110,input_shape = (275, 1),kernel_size = 114,activation = 'relu'))
model.add(MaxPooling1D(pool_size = (2)))
model.add(Flatten())
#model.add(Dropout(rate=0.5))
model.add(Dense(output_dim = 220,activation = 'relu'))
model.add(Dropout(rate=0.1))
model.add(Dense(output_dim = 1,activation = 'sigmoid'))
model.add(Dropout(rate=0.1))
model.compile(optimizer = 'adam',loss = 'binary_crossentropy' ,metrics = ['accuracy'])
model.summary()
cnnhistory=model.fit(x_traincnn, y_train, batch_size=128, epochs=4, validation_data=(x_testcnn, y_test))
y_pred = model.predict(x_testcnn)
y_pred = (y_pred > 0.5)
plt.plot(cnnhistory.history['loss'])
plt.plot(cnnhistory.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
